{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRABALHO AVALIATIVO 2 - INTELIGÊNCIA ARTIFICIAL\n",
    "**Acadêmicos:**\n",
    "- Guilherme Farias Stefani\n",
    "- Henrique Baptista de Oliveira\n",
    "- Henrique Cardoso Zanette\n",
    "- Jhonata Saraiva Peres\n",
    "- Lucas Dellatorre de Freitas\n",
    "\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bibliotecas python nescessarias para utilização deste notebook:**\n",
    "\n",
    "- **Pandas:** Para leitura do DataSet\n",
    "\n",
    "- **Unidecode:** Para normalização dos textos\n",
    "\n",
    "- **Regex:** Para normalização dos textos\n",
    "     \n",
    "- **Nltk:** Para executar os algortmos de machine learning\n",
    "\n",
    "**Rodar no powershell como administrador:**\n",
    "\n",
    "> - pip install pandas\n",
    "> - pip install unidecode\n",
    "> - pip install regex\n",
    "> - pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import unidecode\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Localização dos arquivos de resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenameDataSet = 'resources/DataSet.xlsx'\n",
    "filenameRegexToBeApplied =  'resources/regexToBeApplied'\n",
    "filenameStopWords = 'resources/stopWords'\n",
    "fileNameDeParas = 'resources/dePara'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- iNICIALIZAÇÃO DO DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = pd.ExcelFile(filenameDataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSetRaw = pd.read_excel(dataSet, sheet_name='DebateGovRS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RTs (texto do rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets = pd.read_excel(dataSet, sheet_name='RT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotulados = pd.read_excel(dataSet, sheet_name='ROTULADO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classificação e Limpeza dos Dados**\n",
    "\n",
    "- Inicialmente, retiramos todos os retweets presentes no dataset;\n",
    "\n",
    "- Em seguida, definimos os tipos de classificação dos dados, conforme abaixo:\n",
    ">   - **Contexto:** Precisa de contexto para ser entendido\n",
    ">   - **Positivo:**  Mensagens positivas: Elogios, enaltecimento de candidato, etc.\n",
    ">   - **Negativo:** Mensagens negativas: Ofensas, xingamentos, desmerecer propostas.\n",
    ">   - **Ironia:** sentido contrario da mensagem\n",
    ">   - **Neutro:** nem negativo nem positivo. Somente descritivo (narração de fatos)\n",
    "\n",
    "- Após a definição dos tipos de classificação, começamos a classificar individualmente e manualmente, um por um;\n",
    "\n",
    "- Depois da classificação individual, realizamos uma revisão geral em grupo, onde foram ponderadas e debatidas as classificações, também de forma manual, percorrendo por todas as linhas do dataset;\n",
    "\n",
    "- Ao final da classificação, inicializamos a normalização dos dados, substituindo as abreviações pelas palavras de referência;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criação dos conjuntos de treino, teste e validação**\n",
    "\n",
    "- A partir de todo o conjunto de dados classificado, foram mantidos apenas os valores positivos e negativos (Ironias e confusões foram removidas)\n",
    "\n",
    "- Ordenamos por ordem alfabetica para retirar os textos duplicados do conjunto de dados\n",
    "\n",
    "- Utilizando o tipo de dado com menor amostras (POSITIVO), foi determinado 70% de suas linhas, a quantidade necessária para o conjunto de treino.\n",
    "\n",
    "- Antes de obter os dados e alocar-los no conjunto de treino, sua ordenação foi aleatorizada para abrangir uma quantidade maior de textos.\n",
    "\n",
    "- Após aleatorizar foram colocados no conjunto de treino, com quantidades iguais de positivos e negativos.\n",
    "\n",
    "- Posteriormente foram criados os conjuntos de testes e validação, ambos com 15% cada, do total de amostras do tipo POSITIVO (com menor amostras), com os valores também ordenados de forma aleatória, mas balanceados entre positivos e negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toLower(input):\n",
    "    return input.lower()\n",
    "\n",
    "def removeLinesBreaks(input):\n",
    "    return re.sub('\\\\n', ' ', input, re.IGNORECASE, re.MULTILINE)\n",
    "\n",
    "def removeDoubleSpaces(input):\n",
    "    return re.sub('\\\\s\\\\s', '', input, re.IGNORECASE, re.MULTILINE)\n",
    "\n",
    "def aplyRegex(input):\n",
    "    regexs = open(filenameRegexToBeApplied, 'r', encoding='UTF-8', newline='\\n')\n",
    "    for regex in regexs.readlines():  \n",
    "        teste = re.sub(regex, ' ', input, re.IGNORECASE, re.MULTILINE)\n",
    "        input = teste\n",
    "    return input\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Faz o de para (explicar brevemente o de para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dePara(input):\n",
    "    deParas = open(fileNameDeParas, 'r', encoding='UTF-8', newline='\\n')\n",
    "    for dePara in deParas.readlines():\n",
    "        dePara = dePara.split('(-*-)')\n",
    "        input = re.sub(dePara[0], dePara[1], input, re.IGNORECASE, re.MULTILINE)\n",
    "    return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove as stops Words (explicar brevemente oq é stop word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords(input):\n",
    "    stopWrods = open(filenameStopWords, 'r', encoding='UTF-8', newline='\\n')\n",
    "    for stopWord in stopWrods.readlines():\n",
    "        stopWord = unidecode.unidecode(stopWord)\n",
    "        stopWord = re.sub('\\n', '', stopWord)\n",
    "        input = re.sub(stopWord, ' ', input, re.IGNORECASE, re.MULTILINE)\n",
    "    return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove todas acentuaçoes(explicar para que)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeAcentuacao(input):\n",
    "    return unidecode.unidecode(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = pd.read_excel(filenameDataSet, sheet_name='SEM RT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "listAux = []\n",
    "\n",
    "for line in dataSet.values:\n",
    "    line[6] = dePara(removeStopWords(removeLinesBreaks(unidecode.unidecode(toLower(line[6])))))\n",
    "    listAux.append(line)\n",
    "    \n",
    "    \n",
    "dataSet = pd.DataFrame(listAux)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
